{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "addressed-dayton",
   "metadata": {},
   "source": [
    "### Goals\n",
    "* Use native tensorflow batching; generate augmentations and pair vectors on-demand using as few external libraries as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "imperial-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "cifar_shape = (None,32,32,3)\n",
    "cifar_shape_x = (1,32,32,3)\n",
    "nfeatures = 64\n",
    "nclasses = 10\n",
    "batchsize = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "adult-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder \n",
    "class Encoder(Model):\n",
    "    def __init__(self, insh=cifar_shape, nb_features=nfeatures):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv_0 = layers.Conv2D(64, kernel_size=3, strides=1, \n",
    "                                     padding='same', activation='relu', input_shape=insh)\n",
    "        self.batch_norm_0 = layers.BatchNormalization()\n",
    "        self.conv_1 = layers.Conv2D(32, kernel_size=3, strides=2, \n",
    "                                     padding='same', activation='relu')\n",
    "        self.conv_2 = layers.Conv2D(32, kernel_size=3, strides=1, \n",
    "                                     padding='same', activation='relu')\n",
    "        self.batch_norm_2 = layers.BatchNormalization()\n",
    "        self.conv_3 = layers.Conv2D(16, kernel_size=3, strides=2, \n",
    "                                     padding='same', activation='relu')\n",
    "        self.batch_norm_3 = layers.BatchNormalization()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense_features = layers.Dense(nb_features)\n",
    "    \n",
    "    def call(self, xin):\n",
    "        x = self.conv_0(xin)\n",
    "        x = self.batch_norm_0(x)\n",
    "        x = self.conv_1(x)\n",
    "        x = self.conv_2(x)\n",
    "        x = self.batch_norm_2(x)\n",
    "        x = self.conv_3(x)\n",
    "        x = self.batch_norm_3(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.dense_features(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "hawaiian-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relation head\n",
    "class RelationHead(Model):\n",
    "    def __init__(self, insh=(None,2*nfeatures)):\n",
    "        super(RelationHead, self).__init__()\n",
    "        self.dense_0 = layers.Dense(128, activation='relu', input_shape=insh)\n",
    "        self.dense_1 = layers.Dense(64, activation='relu')\n",
    "        self.batch_norm_1 = layers.BatchNormalization()\n",
    "        self.dense_2 = layers.Dense(64, activation='relu')\n",
    "        self.dense_3 = layers.Dense(32, activation='relu')\n",
    "        self.dense_4 = layers.Dense(8, activation='relu')\n",
    "        self.batch_norm_4 = layers.BatchNormalization()\n",
    "        self.relation = layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "    def call(self, xin):\n",
    "        x = self.dense_0(xin)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.batch_norm_1(x)\n",
    "        x = self.dense_2(x)\n",
    "        x = self.dense_3(x)\n",
    "        x = self.dense_4(x)\n",
    "        x = self.batch_norm_4(x)\n",
    "        return self.relation(x)\n",
    "\n",
    "class SmallRel(Model):\n",
    "    def __init__(self, insh=(None,2*nfeatures)):\n",
    "        super(SmallRel, self).__init__()\n",
    "        self.dense_in = layers.Dense(128, activation='relu', input_shape=insh)\n",
    "        self.dense_1 = layers.Dense(256, activation='relu')\n",
    "        self.batch_norm_1 = layers.BatchNormalization()\n",
    "        self.dense_out = layers.Dense(1, activation='sigmoid')\n",
    "   \n",
    "    def call(self, xin):\n",
    "        x = self.dense_in(xin)\n",
    "        x = self.dense_1(x)\n",
    "        x = self.batch_norm_1(x)\n",
    "        return self.dense_out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "differential-month",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset preparation\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "(train_ds, _),(test_ds, __) = cifar10.load_data()\n",
    "train_shape = train_ds.shape\n",
    "test_shape = test_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "studied-welsh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3125, shape=(), dtype=int64)\n",
      "tf.Tensor(625, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.data import Dataset\n",
    "train_ds = Dataset.from_tensor_slices(train_ds)\n",
    "train_ds = train_ds.shuffle(1000,reshuffle_each_iteration=True)\n",
    "train_ds = train_ds.map(lambda x: x/255)\n",
    "train_ds = train_ds.batch(batchsize)\n",
    "test_ds = Dataset.from_tensor_slices(test_ds)\n",
    "test_ds = test_ds.shuffle(1000,reshuffle_each_iteration=True)\n",
    "test_ds = test_ds.map(lambda x: x/255)\n",
    "test_ds = test_ds.batch(batchsize)\n",
    "print(train_ds.cardinality())\n",
    "print(test_ds.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "specific-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "import tensorflow as tf\n",
    "def randint(max=1, min=0):\n",
    "    return int(min + (tf.random.uniform([1]) * max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "subjective-border",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch augmentation and pair sampling\n",
    "from numpy import min as np_min, max as np_max\n",
    "\n",
    "def channel_norm(im):\n",
    "    rows,cols,channels = im.shape\n",
    "    for c in range(channels):\n",
    "        channel_max = np_max(im[:,:,c])\n",
    "        channel_min = np_min(im[:,:,c])\n",
    "        if channel_max > channel_min: # prevents division by zero\n",
    "            im[:,:,c] = (im[:,:,c] - channel_min) / (channel_max - channel_min)\n",
    "    return im\n",
    "\n",
    "# convert single channel images to rgb, return channelwise normalized array\n",
    "def preprocess(im):\n",
    "    if len(im.shape) == 2:\n",
    "        im = tf.image.grayscale_to_rgb(im)\n",
    "    return channel_norm(im)\n",
    "\n",
    "# jitter hue,saturation,value,contrast\n",
    "def color_jitter(im, h=0.5, s=0.3, v=0.2, c=0.2):\n",
    "    im = tf.image.random_hue(im,h)\n",
    "    im = tf.image.random_saturation(im, 1-s, 1+s)\n",
    "    im = tf.image.random_brightness(im, v)\n",
    "    return tf.image.random_contrast(im,1-c,1+c)\n",
    "\n",
    "# convert a proportion p of inputs to 3-channel grayscale\n",
    "def decolorize(im, p=0.5):\n",
    "    if tf.random.uniform([1]) < p:\n",
    "        return tf.image.grayscale_to_rgb(tf.image.rgb_to_grayscale(im))\n",
    "    else:\n",
    "        return im\n",
    "\n",
    "# crop and resize by bounded random parameters\n",
    "def crop_resize(im, cl=0.3,ch=1.0,al=3/4,ah=4/3):\n",
    "    h,w,channels = im.shape\n",
    "    aspect,crop = tf.random.uniform([2])\n",
    "    aspect = al + (ah-al)*aspect\n",
    "    target_h = h * aspect\n",
    "    target_w = w * (1/aspect)\n",
    "    crop = cl + (ch-cl)*crop\n",
    "    crop_h, crop_w = target_h * crop, target_w * crop\n",
    "    crop_h, crop_w = int(min([crop_h, h-1])), int(min([crop_w, w-1]))\n",
    "    im = tf.image.random_crop(im, [crop_h,crop_w,channels])\n",
    "    return tf.image.resize(im, [h, w])\n",
    "\n",
    "# apply a horizontal flip to some proportion p of inputs\n",
    "def horizontal_flip(im, p=0.5):\n",
    "    if tf.random.uniform([1]) < p:\n",
    "        return tf.image.flip_left_right(im)\n",
    "    else:\n",
    "        return im\n",
    "\n",
    "# apply some intensity of noise between lo and hi to the input image\n",
    "def apply_noise(im, lo=0.0,hi=0.4):\n",
    "    pass\n",
    "\n",
    "def augmentation_sequence(im, numpy=False):\n",
    "    if numpy == False:\n",
    "        im = im.numpy()\n",
    "    im = preprocess(im)\n",
    "    im = color_jitter(im)\n",
    "    im = decolorize(im)\n",
    "    im = crop_resize(im)\n",
    "    im = horizontal_flip(im)\n",
    "    #im = apply_noise(im)\n",
    "    return im\n",
    "\n",
    "# apply all augment functions nb_augment times to each image in a batch\n",
    "def augment(batch, nb_augment = 16):\n",
    "    augmented_batch = []\n",
    "    for i in range(batch.shape[0]):\n",
    "        x = batch[i]\n",
    "        augmented_batch.append(x)\n",
    "        for j in range(1,nb_augment):\n",
    "            aug_x = augmentation_sequence(x)\n",
    "            augmented_batch.append(aug_x)\n",
    "    return tf.stack(augmented_batch, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "floating-shanghai",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# used to generate graphics for a ppt\\nfrom skimage.io import imread,imsave\\nfrom os import path\\nfrom glob import glob\\npath_to = '/home/delphi/Desktop/axle/project_proposal'\\nparticle_pattern = 'extract_particles_*.jpg'\\nglob_pattern = path.join(path_to, particle_pattern)\\nprint(glob_pattern)\\nparticle_paths = [p for p in glob(glob_pattern) if p[-5] in [str(i) for i in range(10)]]\\n#print(particle_paths)\\nprint(f'identified {len(particle_paths)} files in {path_to} matching pattern {particle_pattern}')\\nk = 5\\nfor p in particle_paths:\\n    im = imread(p)\\n    for i in range(k):\\n        augmentation = augmentation_sequence(im, numpy=True)\\n        aug_p = p[:-4] + f'_{i}aug' + p[-4:]\\n        imsave(aug_p, augmentation)\\n\\nfor p in particle_paths:\\n    for i in range(k):\\n        aug_p = p[:-4] + f'_{i}aug' + p[-4:]\\n        augmentation = imread(aug_p)\\n        res_aug = tf.image.resize(augmentation, (250,250))\\n        res_p = aug_p[:-4] + '_res' + aug_p[-4:]\\n        imsave(res_p, res_aug)\\n\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# used to generate graphics for a ppt\n",
    "from skimage.io import imread,imsave\n",
    "from os import path\n",
    "from glob import glob\n",
    "path_to = '/home/delphi/Desktop/axle/project_proposal'\n",
    "particle_pattern = 'extract_particles_*.jpg'\n",
    "glob_pattern = path.join(path_to, particle_pattern)\n",
    "print(glob_pattern)\n",
    "particle_paths = [p for p in glob(glob_pattern) if p[-5] in [str(i) for i in range(10)]]\n",
    "#print(particle_paths)\n",
    "print(f'identified {len(particle_paths)} files in {path_to} matching pattern {particle_pattern}')\n",
    "k = 5\n",
    "for p in particle_paths:\n",
    "    im = imread(p)\n",
    "    for i in range(k):\n",
    "        augmentation = augmentation_sequence(im, numpy=True)\n",
    "        aug_p = p[:-4] + f'_{i}aug' + p[-4:]\n",
    "        imsave(aug_p, augmentation)\n",
    "\n",
    "for p in particle_paths:\n",
    "    for i in range(k):\n",
    "        aug_p = p[:-4] + f'_{i}aug' + p[-4:]\n",
    "        augmentation = imread(aug_p)\n",
    "        res_aug = tf.image.resize(augmentation, (250,250))\n",
    "        res_p = aug_p[:-4] + '_res' + aug_p[-4:]\n",
    "        imsave(res_p, res_aug)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "postal-passenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# optional - sanity check on batch augmentation\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nfrom timeit import timeit\\nw=10\\nh=10\\nfig=plt.figure(figsize=(8, 8))\\ncols = 5\\nrows = 4\\ns = randint(train_shape[0]-rows-1)\\nb = 0\\ntimes = 0.0\\nfor batch in train_ds:\\n    b += 1\\n    times += timeit(lambda: augment(batch, nb_augment=cols), number = 1)\\n    if b % 10 == 0:\\n        print(b)\\nprint(b)\\nprint(batch.shape)\\nprint(times / b)\\nfor i in range(0, cols*rows):\\n    img = augmented_batch[i]\\n    fig.add_subplot(rows, cols, i+1)\\n    plt.imshow(img)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# optional - sanity check on batch augmentation\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from timeit import timeit\n",
    "w=10\n",
    "h=10\n",
    "fig=plt.figure(figsize=(8, 8))\n",
    "cols = 5\n",
    "rows = 4\n",
    "s = randint(train_shape[0]-rows-1)\n",
    "b = 0\n",
    "times = 0.0\n",
    "for batch in train_ds:\n",
    "    b += 1\n",
    "    times += timeit(lambda: augment(batch, nb_augment=cols), number = 1)\n",
    "    if b % 10 == 0:\n",
    "        print(b)\n",
    "print(b)\n",
    "print(batch.shape)\n",
    "print(times / b)\n",
    "for i in range(0, cols*rows):\n",
    "    img = augmented_batch[i]\n",
    "    fig.add_subplot(rows, cols, i+1)\n",
    "    plt.imshow(img)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "terminal-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "# pair two input images\n",
    "def pair_x(x1,x2,insh):#insh = cifar_shape_x\n",
    "    if x1.shape != insh:\n",
    "        x1 = tf.reshape(x1,insh)\n",
    "    if x2.shape != insh:\n",
    "        x2 = tf.reshape(x2, insh)\n",
    "    return tf.concat([x1,x2], 0)\n",
    "\n",
    "# aggregates two feature vectors together with a linear concatenation\n",
    "def aggregate(z1,z2):\n",
    "    return tf.concat([z1,z2], 0)\n",
    "    #return tf.reshape(ag, (1,2*nfeatures))\n",
    "\n",
    "# from M*K encoded augmented inputs, sample M*K(K-1)/2 positive and negative pairs \n",
    "def positive_subsamples(encoded_batch, M, K):\n",
    "    N = M * K\n",
    "    return [encoded_batch[i:i+K] for i in range(0,N,K)]\n",
    "\n",
    "def negative_subsamples(encoded_batch, M, K):\n",
    "    N = M * K\n",
    "    return [[encoded_batch[(i+j+j*K) % N] for j in range(K)] \n",
    "                 for i in range(0,N,K)]\n",
    "\n",
    "def sample_aggregate_pairs(subsamples, K):\n",
    "    return list(chain(*[\n",
    "        [aggregate(sub[i],sub[j]) for i in range(K) for j in range(i+1,K)] for sub in subsamples\n",
    "    ]))\n",
    "\n",
    "def sample(encoded_batch, M, K):\n",
    "    pos = sample_aggregate_pairs(positive_subsamples(encoded_batch,M,K),K)\n",
    "    neg = sample_aggregate_pairs(negative_subsamples(encoded_batch,M,K),K)\n",
    "    return pos + neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "clinical-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# optional - sanity check on pairing and aggregation\\nfrom math import floor\\nM = 64\\nK = 16\\nencoded_batch = [i/K for i in range(M*K)]\\npos = positive_subsamples(encoded_batch,M,K)\\nneg = negative_subsamples(encoded_batch,M,K)\\npos_pairs = sample_aggregate_pairs(pos, K)\\nneg_pairs = sample_aggregate_pairs(neg, K)\\npairs = sample(encoded_batch, M, K)\\nprint(len(list(chain(*pos))),len(list(chain(*neg))))\\nprint(len(pos_pairs), len(neg_pairs))\\nprint(len(pairs))\\n\\nT = 1000\\nt = timeit(lambda: sample(encoded_batch,M,K), number=T)\\nprint(t/T)\\n'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# optional - sanity check on pairing and aggregation\n",
    "from math import floor\n",
    "M = 64\n",
    "K = 16\n",
    "encoded_batch = [i/K for i in range(M*K)]\n",
    "pos = positive_subsamples(encoded_batch,M,K)\n",
    "neg = negative_subsamples(encoded_batch,M,K)\n",
    "pos_pairs = sample_aggregate_pairs(pos, K)\n",
    "neg_pairs = sample_aggregate_pairs(neg, K)\n",
    "pairs = sample(encoded_batch, M, K)\n",
    "print(len(list(chain(*pos))),len(list(chain(*neg))))\n",
    "print(len(pos_pairs), len(neg_pairs))\n",
    "print(len(pairs))\n",
    "\n",
    "T = 1000\n",
    "t = timeit(lambda: sample(encoded_batch,M,K), number=T)\n",
    "print(t/T)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "important-repair",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# optional - sanity check on model evaluation\\ni,j = randint(train_x.shape[0]),randint(train_x.shape[0])\\n\\nim_pair = pair_x(train_x[i],train_x[j])\\nprint(im_pair.shape)\\nfeature_tuple = encoder(im_pair/255)\\npair = aggregate(feature_tuple)\\nprint(pair.shape)\\nrelhead(pair)\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# optional - sanity check on model evaluation\n",
    "i,j = randint(train_x.shape[0]),randint(train_x.shape[0])\n",
    "\n",
    "im_pair = pair_x(train_x[i],train_x[j])\n",
    "print(im_pair.shape)\n",
    "feature_tuple = encoder(im_pair/255)\n",
    "pair = aggregate(feature_tuple)\n",
    "print(pair.shape)\n",
    "relhead(pair)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-breast",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "100 loss: 0.7154995203018188 acc: 0.4970833659172058\n",
      "200 loss: 0.7046627998352051 acc: 0.5000261664390564\n",
      "300 loss: 0.7009899616241455 acc: 0.49973973631858826\n"
     ]
    }
   ],
   "source": [
    "# train it\n",
    "\n",
    "# hyperparameters\n",
    "rate = 1e-3\n",
    "epochs = 1\n",
    "M = batchsize\n",
    "K = 4\n",
    "interval = 100\n",
    "print(1)\n",
    "\n",
    "# refresh datasets\n",
    "for _ in train_ds:\n",
    "    pass\n",
    "for _ in test_ds:\n",
    "    pass\n",
    "print(2)\n",
    "\n",
    "# build models\n",
    "encoder = Encoder()\n",
    "encoder.build(cifar_shape)\n",
    "relhead = SmallRel()\n",
    "relhead.build((None,2*nfeatures))\n",
    "print(3)\n",
    "\n",
    "# do training\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(rate)\n",
    "metric_acc = tf.keras.metrics.BinaryAccuracy()\n",
    "metric_loss = tf.keras.metrics.BinaryCrossentropy()\n",
    "\n",
    "print(4)\n",
    "for epoch in range(epochs):\n",
    "    metric_acc.reset_states()\n",
    "    metric_loss.reset_states()\n",
    "    i = 0\n",
    "    for batch in train_ds:\n",
    "        i += 1\n",
    "        augmented_batch = augment(batch, K)\n",
    "        with tf.GradientTape() as tape:\n",
    "            encoded_batch = encoder(augmented_batch, training=True)\n",
    "            pairs = sample(encoded_batch, M, K)\n",
    "            pairs_tensor = tf.stack(pairs)\n",
    "            scores = relhead(pairs_tensor, training=True)\n",
    "            targets = [1] * (len(pairs)//2) + [0] * (len(pairs)//2)\n",
    "            err = loss(targets,scores)\n",
    "        encoder_grad, relhead_grad = tape.gradient(err, \n",
    "            [encoder.trainable_weights,relhead.trainable_weights])\n",
    "        optimizer.apply_gradients(zip(encoder_grad, encoder.trainable_weights))\n",
    "        optimizer.apply_gradients(zip(relhead_grad, relhead.trainable_weights))\n",
    "        metric_acc.update_state(targets,scores)\n",
    "        metric_loss.update_state(targets,scores)\n",
    "        if i % interval == 0:\n",
    "            print(\n",
    "                f'{i} '\n",
    "                f'loss: {metric_loss.result()}'\n",
    "                f' acc: {metric_acc.result()}'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-methodology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
